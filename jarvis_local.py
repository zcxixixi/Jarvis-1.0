#!/usr/bin/env python3
"""
JARVIS æœ¬åœ°è¯­éŸ³ç‰ˆ - ä½¿ç”¨ macOS è‡ªå¸¦ TTS
å®Œå…¨ç¦»çº¿è¿è¡Œï¼Œæ— éœ€ç½‘ç»œ
"""
import asyncio
import subprocess
import os
import tempfile
import re
import numpy as np
from faster_whisper import WhisperModel
import pyaudio
import wave
from jarvis_core import JarvisCore
from config import Config
from rich.console import Console

console = Console()

class JarvisLocal:
    def __init__(self):
        console.print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–...", style="yellow")
        
        # Initialize Whisper model (local STT)
        console.print("ğŸ“¥ åŠ è½½è¯­éŸ³è¯†åˆ«æ¨¡å‹...", style="dim")
        self.whisper = WhisperModel("base", device="cpu", compute_type="int8")
        console.print("âœ… Whisper å·²åŠ è½½", style="green")
        
        # Initialize LLM
        self.jarvis = JarvisCore()
        console.print(f"âœ… LLM å·²åŠ è½½: {self.jarvis.model}", style="green")
        
        # Audio settings
        self.sample_rate = 16000
        self.chunk_size = 1024
        
        # Initialize PyAudio
        self.audio = pyaudio.PyAudio()
        
        console.print("âœ… ç³»ç»Ÿå°±ç»ªï¼", style="bold green")

    def speak(self, text):
        """ä½¿ç”¨ macOS say å‘½ä»¤æœ—è¯»"""
        if not text.strip():
            return
        # ä½¿ç”¨ä¸­æ–‡è¯­éŸ³ Tingting
        subprocess.run(["say", "-v", "Tingting", text], check=True)

    def record_audio(self, duration=8, silence_threshold=500, silence_duration=1.5):
        """å½•åˆ¶éŸ³é¢‘"""
        console.print("ğŸ‘‚ æ­£åœ¨è†å¬...", style="bold cyan")
        
        stream = self.audio.open(
            format=pyaudio.paInt16,
            channels=1,
            rate=self.sample_rate,
            input=True,
            frames_per_buffer=self.chunk_size
        )
        
        frames = []
        silent_chunks = 0
        has_speech = False
        max_chunks = int(self.sample_rate / self.chunk_size * duration)
        silence_chunks_threshold = int(self.sample_rate / self.chunk_size * silence_duration)
        
        for i in range(max_chunks):
            data = stream.read(self.chunk_size, exception_on_overflow=False)
            frames.append(data)
            
            audio_data = np.frombuffer(data, dtype=np.int16)
            level = np.abs(audio_data).mean()
            
            if level > silence_threshold:
                has_speech = True
                silent_chunks = 0
            else:
                silent_chunks += 1
            
            if has_speech and silent_chunks > silence_chunks_threshold:
                break
        
        stream.stop_stream()
        stream.close()
        
        if not has_speech:
            return None
        
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as fp:
            temp_file = fp.name
            
        wf = wave.open(temp_file, 'wb')
        wf.setnchannels(1)
        wf.setsampwidth(self.audio.get_sample_size(pyaudio.paInt16))
        wf.setframerate(self.sample_rate)
        wf.writeframes(b''.join(frames))
        wf.close()
        
        return temp_file

    def transcribe(self, audio_file):
        """æœ¬åœ°è¯­éŸ³è¯†åˆ«"""
        console.print("ğŸ”„ è¯†åˆ«ä¸­...", style="dim")
        
        segments, info = self.whisper.transcribe(audio_file, language="zh")
        text = "".join([segment.text for segment in segments]).strip()
        
        if os.path.exists(audio_file):
            os.remove(audio_file)
        
        return text

    def listen(self):
        """ç›‘å¬å¹¶è¯†åˆ«"""
        audio_file = self.record_audio()
        
        if not audio_file:
            console.print("ğŸ¤· æ²¡å¬åˆ°...", style="dim")
            return None
        
        text = self.transcribe(audio_file)
        
        if text:
            console.print(f"ğŸ—£ï¸  ä½ : {text}", style="bold green")
        else:
            console.print("ğŸ¤· æ²¡å¬æ¸…...", style="dim")
            
        return text if text else None

    def chat_and_speak(self, user_input):
        """å¯¹è¯å¹¶æœ—è¯»"""
        console.print("ğŸ’­ æ€è€ƒä¸­...", style="dim")
        
        # ä½¿ç”¨æµå¼å“åº”å¹¶æŒ‰å¥å­æœ—è¯»
        sentence_buffer = ""
        sentence_endings = re.compile(r'[ã€‚ï¼ï¼Ÿ.!?\n]')
        
        for chunk in self.jarvis.chat_stream(user_input):
            sentence_buffer += chunk
            console.print(chunk, end="", style="cyan")
            
            while sentence_endings.search(sentence_buffer):
                match = sentence_endings.search(sentence_buffer)
                if match:
                    end_pos = match.end()
                    sentence = sentence_buffer[:end_pos].strip()
                    sentence_buffer = sentence_buffer[end_pos:]
                    
                    if sentence:
                        self.speak(sentence)
        
        console.print()
        
        if sentence_buffer.strip():
            self.speak(sentence_buffer.strip())

    def run(self):
        console.print("\nğŸš€ Jarvis æœ¬åœ°è¯­éŸ³æ¨¡å¼ (macOS TTS)", style="bold green")
        console.print("ğŸ’¬ å¼€å§‹è¯´è¯å§ï¼è¯´'é€€å‡º'ç»“æŸ", style="cyan")
        
        while True:
            try:
                user_input = self.listen()
                
                if not user_input:
                    continue
                    
                if any(word in user_input for word in ['é€€å‡º', 'å†è§', 'æ‹œæ‹œ']):
                    self.speak("å¥½çš„ï¼Œå†è§ã€‚")
                    break
                
                self.chat_and_speak(user_input)
                
            except KeyboardInterrupt:
                console.print("\nğŸ‘‹ å†è§ï¼", style="cyan")
                break
            except Exception as e:
                console.print(f"âŒ é”™è¯¯: {e}", style="red")
                if Config.DEBUG:
                    import traceback
                    traceback.print_exc()
    
    def __del__(self):
        try:
            self.audio.terminate()
        except:
            pass

if __name__ == "__main__":
    client = JarvisLocal()
    client.run()
