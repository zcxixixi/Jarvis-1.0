#!/usr/bin/env python3
"""
End-to-End Voice Demo (from SKILL.md)
"""
import asyncio
import json
import wave
import sys
import os
import pyaudio

# Add project root to path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
import time

from jarvis_assistant.services.doubao.websocket import DoubaoRealtimeJarvis
from jarvis_assistant.services.doubao.protocol import DoubaoMessage, MsgType, EventType, SerializationBits
from jarvis_assistant.core.agent import get_agent
from jarvis_assistant.services.doubao.tts_v3 import DoubaoTTSV1

INPUT_WAV = "demo_input.wav"
OUTPUT_WAV = "demo_output.wav"

# ğŸ”¥ Global TTS singleton for connection reuse (saves ~125ms per request)
_tts_instance = None

async def get_tts():
    """Get or create persistent TTS connection"""
    global _tts_instance
    if _tts_instance is None:
        _tts_instance = DoubaoTTSV1()
    return _tts_instance

# --- COPY FROM SKILL.MD BEGIN ---
class GoldenVoiceDemo(DoubaoRealtimeJarvis):
    def __init__(self):
        super().__init__()
        self.final_text = None
        self.completion_event = asyncio.Event()

    # ğŸŸ¢ CRITICAL: Disable base class audio loops to prevent interference
    def setup_audio(self): pass
    async def send_audio_loop(self): pass

    async def receive_loop(self):
        print("ğŸ§ Listening for ASR events...")
        async for message in self.ws:
            if not self.is_running: break
            if isinstance(message, str): continue
            
            try:
                msg = DoubaoMessage.from_bytes(message)
                if msg.serialization == SerializationBits.JSON:
                    event = json.loads(msg.payload)
                    # Dialog API returns results in 'results' list
                    if 'results' in event and event['results']:
                        res = event['results'][0]
                        text = res.get('text', '')
                        is_interim = res.get('is_interim', True)
                        if text:
                            print(f"[ASR] {text} {'(interim)' if is_interim else 'âœ…'}")
                            if not is_interim:
                                self.final_text = text
                                print(f"[PERF] ğŸ ASR Final: {time.time():.3f}")  # LOG 1
                                self.completion_event.set()
            except: pass

    async def run_pipeline(self, wav_path):
        # ğŸŸ¢ CRITICAL: Use create_task, NOT await, or it blocks forever!
        asyncio.create_task(self.connect())
        await asyncio.sleep(2) # Allow connection logic to start
        
        with wave.open(wav_path, 'rb') as wf:
            data = wf.readframes(wf.getnframes())
            
        chunk_size = 3200
        for i in range(0, len(data), chunk_size):
            if self.completion_event.is_set(): break  # âš¡ Break if ASR done
            msg = DoubaoMessage(type=MsgType.AudioOnlyClient, event=EventType.TaskRequest,
                               session_id=self.session_id, payload=data[i:i+chunk_size])
            await self.ws.send(msg.marshal())
            await asyncio.sleep(0.05) # Slightly faster
            
        # Send silence (Endpoint trigger)
        for _ in range(15):
             if self.completion_event.is_set(): break  # âš¡ Break if ASR done
             msg = DoubaoMessage(type=MsgType.AudioOnlyClient, event=EventType.TaskRequest,
                                session_id=self.session_id, payload=b'\x00'*3200)
             await self.ws.send(msg.marshal())
             await asyncio.sleep(0.1)
             
        try:
            await asyncio.wait_for(self.completion_event.wait(), timeout=10)
        except asyncio.TimeoutError:
            print("âŒ ASR Timeout", flush=True)
            return None

        print(f"ğŸ§  Processing: {self.final_text}")
        t_start_agent = time.time()
        print(f"[PERF] ğŸš€ Agent Start: {t_start_agent:.3f}") # LOG 2
        
        # ğŸ¯ Context-aware transitional phrases
        def get_transition_phrase(query: str) -> str:
            """Generate contextual transition phrase based on query intent"""
            import random
            
            # Intent-specific transitions
            if any(kw in query for kw in ["è‚¡ä»·", "è‚¡ç¥¨", "å¸ä»·", "è¡Œæƒ…", "ä»·æ ¼"]):
                return random.choice([
                    "å¥½çš„ï¼Œæ­£åœ¨æŸ¥è¯¢å®æ—¶è¡Œæƒ…",
                    "ç¨ç­‰ï¼Œé©¬ä¸Šä¸ºæ‚¨æŸ¥è¯¢è‚¡ä»·",
                    "æ”¶åˆ°ï¼Œæ­£åœ¨è¿æ¥è¡Œæƒ…æœåŠ¡å™¨",
                    "è®©æˆ‘çœ‹çœ‹æœ€æ–°çš„å¸‚åœºæ•°æ®"
                ])
            
            elif any(kw in query for kw in ["å¤©æ°”", "æ¸©åº¦", "ä¸‹é›¨", "å†·", "çƒ­"]):
                return random.choice([
                    "å¥½çš„ï¼Œæ­£åœ¨æŸ¥è¯¢å¤©æ°”æƒ…å†µ",
                    "ç¨ç­‰ï¼Œé©¬ä¸Šä¸ºæ‚¨æŸ¥è¯¢å¤©æ°”",
                    "è®©æˆ‘çœ‹çœ‹å¤©æ°”é¢„æŠ¥",
                    "æ­£åœ¨è·å–æ°”è±¡æ•°æ®"
                ])
            
            elif any(kw in query for kw in ["æ’­æ”¾", "éŸ³ä¹", "æ­Œ", "å¬"]):
                return random.choice([
                    "å¥½çš„ï¼Œæ­£åœ¨ä¸ºæ‚¨å‡†å¤‡éŸ³ä¹",
                    "é©¬ä¸Šä¸ºæ‚¨æ’­æ”¾",
                    "æ­£åœ¨æœç´¢æ­Œæ›²",
                    "æ”¶åˆ°ï¼Œæ­£åœ¨è¿æ¥éŸ³ä¹æœåŠ¡"
                ])
            
            elif any(kw in query for kw in ["æœç´¢", "æŸ¥ä¸€ä¸‹", "æ‰¾ä¸€ä¸‹"]):
                return random.choice([
                    "å¥½çš„ï¼Œæ­£åœ¨ä¸ºæ‚¨æœç´¢",
                    "ç¨ç­‰ï¼Œé©¬ä¸Šä¸ºæ‚¨æŸ¥è¯¢",
                    "æ­£åœ¨æœç´¢ç›¸å…³ä¿¡æ¯",
                    "è®©æˆ‘å¸®æ‚¨æ‰¾æ‰¾"
                ])
            
            elif any(kw in query for kw in ["è®¡ç®—", "ä¹˜", "åŠ ", "å‡", "é™¤"]):
                return random.choice([
                    "å¥½çš„ï¼Œè®©æˆ‘ç®—ä¸€ä¸‹",
                    "ç¨ç­‰ï¼Œæ­£åœ¨è®¡ç®—",
                    "é©¬ä¸Šä¸ºæ‚¨è®¡ç®—ç»“æœ"
                ])
            
            elif any(kw in query for kw in ["æé†’", "æ—¥ç¨‹", "å®‰æ’"]):
                return random.choice([
                    "å¥½çš„ï¼Œæ­£åœ¨ä¸ºæ‚¨è®¾ç½®æé†’",
                    "æ”¶åˆ°ï¼Œé©¬ä¸Šä¸ºæ‚¨å®‰æ’",
                    "æ­£åœ¨æ·»åŠ åˆ°æ—¥ç¨‹"
                ])
            
            elif any(kw in query for kw in ["æ–°é—»", "å¤´æ¡", "çƒ­ç‚¹"]):
                return random.choice([
                    "å¥½çš„ï¼Œæ­£åœ¨è·å–æœ€æ–°æ–°é—»",
                    "ç¨ç­‰ï¼Œé©¬ä¸Šä¸ºæ‚¨æŸ¥è¯¢çƒ­ç‚¹",
                    "æ­£åœ¨è¿æ¥æ–°é—»æœåŠ¡"
                ])
            
            # Generic fallback
            else:
                return random.choice([
                    "å¥½çš„ï¼Œè®©æˆ‘æƒ³æƒ³",
                    "ç¨ç­‰ï¼Œæ­£åœ¨å¤„ç†",
                    "æ”¶åˆ°ï¼Œé©¬ä¸Šä¸ºæ‚¨å¤„ç†",
                    "å¥½çš„ï¼Œæˆ‘æ¥çœ‹çœ‹"
                ])
        
        # Detect if this needs a transition (tool queries)
        # Fix: Ensure self.final_text is not None before checking
        if not self.final_text:
             print("âŒ Error: No text recognized")
             return None

        needs_transition = any(keyword in self.final_text for keyword in 
                              ["æŸ¥è¯¢", "è‚¡ä»·", "å¤©æ°”", "æœç´¢", "è®¡ç®—", "æé†’", "æ’­æ”¾", "å¤šå°‘", "æ€ä¹ˆæ ·", "æ–°é—»"])
        
        if needs_transition:
            transition = get_transition_phrase(self.final_text)
            print(f"ğŸ’¬ [Transition]: {transition}")
            # âš¡ Play pre-cached audio instead of TTS (saves ~500ms)
            asyncio.create_task(play_cached_transition(transition))
            await asyncio.sleep(0.1)  # Minimal delay
        
        agent = get_agent()
        response = await agent.run(self.final_text)
        print(f"[PERF] âœ… Agent End: {time.time():.3f} (Duration: {(time.time()-t_start_agent)*1000:.0f}ms)") # LOG 3
        return response

    async def run_text(self, text):
        """Run pipeline with direct text input (Bypass ASR)"""
        print(f"ğŸ§  Processing (Text Input): {text}")
        t_start_agent = time.time()
        print(f"[PERF] ğŸš€ Agent Start: {t_start_agent:.3f}")

        # Check for transitions
        await play_cached_transition(text)

        agent = get_agent()
        response = await agent.run(text)
        
        t_end_agent = time.time()
        print(f"[PERF] âœ… Agent End: {t_end_agent:.3f} (Duration: {(t_end_agent-t_start_agent)*1000:.0f}ms)")
        
        return response

# Transition text -> cache file mapping
TRANSITION_CACHE = {
    "å¥½çš„ï¼Œæ­£åœ¨æŸ¥è¯¢å®æ—¶è¡Œæƒ…": "stock_1.wav",
    "ç¨ç­‰ï¼Œé©¬ä¸Šä¸ºæ‚¨æŸ¥è¯¢è‚¡ä»·": "stock_2.wav",
    "æ”¶åˆ°ï¼Œæ­£åœ¨è¿æ¥è¡Œæƒ…æœåŠ¡å™¨": "stock_3.wav",
    "è®©æˆ‘çœ‹çœ‹æœ€æ–°çš„å¸‚åœºæ•°æ®": "stock_4.wav",
    "å¥½çš„ï¼Œæ­£åœ¨æŸ¥è¯¢å¤©æ°”æƒ…å†µ": "weather_1.wav",
    "ç¨ç­‰ï¼Œé©¬ä¸Šä¸ºæ‚¨æŸ¥è¯¢å¤©æ°”": "weather_2.wav",
    "è®©æˆ‘çœ‹çœ‹å¤©æ°”é¢„æŠ¥": "weather_3.wav",
    "æ­£åœ¨è·å–æ°”è±¡æ•°æ®": "weather_4.wav",
    "å¥½çš„ï¼Œæ­£åœ¨ä¸ºæ‚¨å‡†å¤‡éŸ³ä¹": "music_1.wav",
    "é©¬ä¸Šä¸ºæ‚¨æ’­æ”¾": "music_2.wav",
    "æ­£åœ¨æœç´¢æ­Œæ›²": "music_3.wav",
    "æ”¶åˆ°ï¼Œæ­£åœ¨è¿æ¥éŸ³ä¹æœåŠ¡": "music_4.wav",
    "å¥½çš„ï¼Œæ­£åœ¨ä¸ºæ‚¨æœç´¢": "search_1.wav",
    "ç¨ç­‰ï¼Œé©¬ä¸Šä¸ºæ‚¨æŸ¥è¯¢": "search_2.wav",
    "æ­£åœ¨æœç´¢ç›¸å…³ä¿¡æ¯": "search_3.wav",
    "è®©æˆ‘å¸®æ‚¨æ‰¾æ‰¾": "search_4.wav",
    "å¥½çš„ï¼Œè®©æˆ‘ç®—ä¸€ä¸‹": "calc_1.wav",
    "ç¨ç­‰ï¼Œæ­£åœ¨è®¡ç®—": "calc_2.wav",
    "é©¬ä¸Šä¸ºæ‚¨è®¡ç®—ç»“æœ": "calc_3.wav",
    "å¥½çš„ï¼Œæ­£åœ¨ä¸ºæ‚¨è®¾ç½®æé†’": "remind_1.wav",
    "æ”¶åˆ°ï¼Œé©¬ä¸Šä¸ºæ‚¨å®‰æ’": "remind_2.wav",
    "æ­£åœ¨æ·»åŠ åˆ°æ—¥ç¨‹": "remind_3.wav",
    "å¥½çš„ï¼Œæ­£åœ¨è·å–æœ€æ–°æ–°é—»": "news_1.wav",
    "ç¨ç­‰ï¼Œé©¬ä¸Šä¸ºæ‚¨æŸ¥è¯¢çƒ­ç‚¹": "news_2.wav",
    "æ­£åœ¨è¿æ¥æ–°é—»æœåŠ¡": "news_3.wav",
    "å¥½çš„ï¼Œè®©æˆ‘æƒ³æƒ³": "generic_1.wav",
    "ç¨ç­‰ï¼Œæ­£åœ¨å¤„ç†": "generic_2.wav",
    "æ”¶åˆ°ï¼Œé©¬ä¸Šä¸ºæ‚¨å¤„ç†": "generic_3.wav",
    "å¥½çš„ï¼Œæˆ‘æ¥çœ‹çœ‹": "generic_4.wav",
}

CACHE_DIR = os.path.expanduser("~/Music/JarvisCache/transitions")

async def play_cached_transition(text: str):
    """Play pre-cached transition audio (instant, no TTS latency)"""
    t_start = time.time()
    
    filename = TRANSITION_CACHE.get(text)
    if not filename:
        print(f"  âš ï¸ No cache for: {text}, falling back to TTS")
        await synthesize_and_play(text)
        return
    
    filepath = os.path.join(CACHE_DIR, filename)
    if not os.path.exists(filepath):
        print(f"  âš ï¸ Cache file missing: {filepath}, falling back to TTS")
        await synthesize_and_play(text)
        return
    
    print(f"[PERF] âš¡ Cached Transition: {time.time():.3f} (Latency: {(time.time()-t_start)*1000:.0f}ms)")
    
    # Play with afplay (macOS) or mpg123 (Linux)
    import platform
    import subprocess
    if platform.system() == "Darwin":
        subprocess.Popen(["afplay", filepath], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    else:
        subprocess.Popen(["mpg123", "-q", filepath], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

async def synthesize_and_play(text):
    """Streaming TTS: Play audio chunks as they arrive (low latency)"""
    t_start_tts = time.time()
    print(f"[PERF] ğŸ—£ï¸ TTS Request: {t_start_tts:.3f}")
    
    # ğŸ”¥ Use global singleton for connection reuse
    tts = await get_tts()
    t_conn = time.time()
    await tts.connect()
    print(f"[PERF] ğŸ”Œ TTS Connected: {time.time():.3f} (Latency: {(time.time()-t_conn)*1000:.0f}ms)")
    
    # ğŸ”¥ Streaming playback: Open audio stream BEFORE receiving data
    p = pyaudio.PyAudio()
    stream = p.open(
        format=pyaudio.paInt16,  # 16-bit
        channels=1,              # Mono
        rate=24000,              # TTS sample rate
        output=True,
        frames_per_buffer=1024
    )
    
    first_chunk = True
    chunk_count = 0
    
    try:
        async for chunk in tts.synthesize(text):
            if first_chunk:
                print(f"[PERF] ğŸµ TTS First Byte: {time.time():.3f} (TTFB: {(time.time()-t_start_tts)*1000:.0f}ms)")
                print("ğŸ”Š Streaming playback...")
                first_chunk = False
            
            # âš¡ Play immediately as chunk arrives
            stream.write(chunk)
            chunk_count += 1
        
        print(f"âœ… Playback complete ({chunk_count} chunks)")
    finally:
        stream.stop_stream()
        stream.close()
        p.terminate()
    
    # ğŸ”¥ Don't close TTS - keep connection alive for reuse!
    # await tts.close()
    print(f"[PERF] ğŸ TTS Total: {(time.time()-t_start_tts)*1000:.0f}ms")

def record_audio(seconds=3):
    print("\n" + "="*60, flush=True)
    print("ğŸ¤ Voice Recorder", flush=True)
    print("="*60, flush=True)
    
    input("Press Enter to start recording...")
    print(f"ğŸ”´ Recording {seconds}s...", flush=True)
    
    p = pyaudio.PyAudio()
    stream = p.open(format=pyaudio.paInt16, channels=1, rate=16000, input=True, frames_per_buffer=1024)
    frames = []
    
    try:
        for i in range(0, int(16000 / 1024 * seconds)):
            data = stream.read(1024)
            frames.append(data)
            if i % 5 == 0: print(".", end="", flush=True)
    except KeyboardInterrupt:
        pass
        
    print("\nâœ… Stopped")
    stream.stop_stream()
    stream.close()
    p.terminate()
    
    with wave.open(INPUT_WAV, 'wb') as wf:
        wf.setnchannels(1)
        wf.setsampwidth(2)
        wf.setframerate(16000)
        wf.writeframes(b''.join(frames))
    print(f"Saved: {INPUT_WAV}")

if __name__ == "__main__":
    record_audio(seconds=4)
    
    demo = GoldenVoiceDemo()
    response = asyncio.run(demo.run_pipeline(INPUT_WAV))
    
    if response:
        asyncio.run(synthesize_and_play(response))
    
    print(f"\n{'='*60}")
    print("âœ… DEMO COMPLETE")
    print(f"{'='*60}")
