"""
Query Router - æŸ¥è¯¢è·¯ç”±å™¨
åè°ƒ S2S å’Œ ASR-Agent-TTS ä¸¤æ¡å¤„ç†è·¯å¾„
Now with semantic intent classification, context resolution, and latency optimizations!
"""
import asyncio
import logging
import os
import time
from typing import Optional, List
from .intent_classifier import IntentClassifier  # Keep as fallback
from .semantic_intent_classifier import get_semantic_classifier, SemanticIntentClassifier
from .context_resolver import get_context_resolver

logger = logging.getLogger(__name__)


# Transitional phrases for better UX during long operations
TRANSITION_PHRASES = {
    "weather": "æ­£åœ¨è·å–å¤©æ°”æ•°æ®",
    "stock": "æ­£åœ¨æŸ¥è¯¢å®æ—¶è¡Œæƒ…",
    "finance": "æ­£åœ¨æŸ¥è¯¢é‡‘èæ•°æ®",
    "search": "è®©æˆ‘åœ¨ç½‘ä¸Šæœç´¢ä¸€ä¸‹",
    "music": "æ­£åœ¨å‡†å¤‡éŸ³ä¹",
    "smart_home": "æ­£åœ¨æ§åˆ¶è®¾å¤‡",
    "news": "æ­£åœ¨è·å–æœ€æ–°æ–°é—»",
    "email": "æ­£åœ¨å‡†å¤‡å‘é€é‚®ä»¶",
    "default": "æ­£åœ¨å¤„ç†æ‚¨çš„è¯·æ±‚ï¼Œè¯·ç¨å€™",
}


class QueryRouter:
    """æŸ¥è¯¢è·¯ç”±å™¨ - æ ¹æ®æ„å›¾é€‰æ‹©å¤„ç†è·¯å¾„ (Upgraded with Semantic AI + Latency Optimizations!)"""
    
    def __init__(self, hybrid_jarvis):
        """
        Args:
            hybrid_jarvis: HybridJarvis å®ä¾‹ï¼ˆæä¾› S2Sã€Agentã€TTS è®¿é—®ï¼‰
        """
        self.jarvis = hybrid_jarvis
        
        # Lazy loading: Don't load classifiers on startup
        self._classifier = None
        self._context_resolver = None
        self._use_semantic = os.getenv("USE_SEMANTIC_CLASSIFIER", "true").lower() == "true"
        
        self.current_path: Optional[str] = None  # "s2s" or "agent"
        self._agent_lock = asyncio.Lock()  # é˜²æ­¢å¹¶å‘ Agent è°ƒç”¨
        
        logger.info(f"âœ… QueryRouter initialized (semantic={'enabled' if self._use_semantic else 'disabled'}, lazy loading)")
    
    @property
    def classifier(self):
        """Lazy load classifier on first use"""
        if self._classifier is None:
            if self._use_semantic:
                try:
                    logger.info("ğŸ”„ Loading semantic classifier...")
                    start = time.time()
                    self._classifier = get_semantic_classifier()
                    elapsed = (time.time() - start) * 1000
                    logger.info(f"âœ… Semantic classifier loaded in {elapsed:.0f}ms")
                except Exception as e:
                    logger.error(f"âŒ Failed to load semantic classifier: {e}")
                    logger.info("âš ï¸ Falling back to keyword classifier")
                    self._classifier = IntentClassifier()
            else:
                self._classifier = IntentClassifier()
                logger.info("âœ… Keyword classifier loaded")
        
        return self._classifier
    
    @property
    def context_resolver(self):
        """Lazy load context resolver on first use"""
        if self._context_resolver is None:
            # Only use context resolver with semantic classifier
            if isinstance(self.classifier, SemanticIntentClassifier):
                self._context_resolver = get_context_resolver()
                logger.info("âœ… Context resolver loaded")
        
        return self._context_resolver
    
    async def route(self, transcription: str):
        """
        è·¯ç”±æŸ¥è¯¢åˆ°åˆé€‚çš„å¤„ç†è·¯å¾„
        Now with context resolution, multi-intent detection, and performance monitoring!
        
        Args:
            transcription: ASR è½¬å½•æ–‡æœ¬
        """
        start_time = time.time()
        print(f"ğŸš¦ [ROUTER] route() called with: {transcription}")
        
        # Step 1: Resolve context (pronouns, references)
        t1 = time.time()
        resolved_text = transcription
        if self.context_resolver:
            resolved_text = self.context_resolver.resolve(transcription)
            if resolved_text != transcription:
                print(f"ğŸ”„ [ROUTER] Context resolved: {transcription} â†’ {resolved_text}")
                logger.info(f"ğŸ”„ Context resolved: {transcription} â†’ {resolved_text}")
        context_time = (time.time() - t1) * 1000
        
        # Step 2: Classify intent
        t2 = time.time()
        intent = self.classifier.classify(resolved_text)
        classify_time = (time.time() - t2) * 1000
        print(f"ğŸš¦ [ROUTER] Intent classified as: {intent}")
        
        # Step 3: Detect multiple intents (if using semantic classifier)
        intents = []
        if hasattr(self.classifier, 'detect_intents'):
            intents = self.classifier.detect_intents(resolved_text)
            if len(intents) > 1:
                print(f"ğŸ¯ [ROUTER] Multi-intent detected: {intents}")
                logger.info(f"ğŸ¯ Multi-intent query: {intents}")
        
        # Performance monitoring
        total_time = (time.time() - start_time) * 1000
        logger.info(f"â±ï¸ [PERF] Context: {context_time:.0f}ms, Classify: {classify_time:.0f}ms, Total: {total_time:.0f}ms")
        
        if total_time > 200:
            logger.warning(f"âš ï¸ [PERF] Slow routing: {total_time:.0f}ms")
        
        if total_time > 200:
            logger.warning(f"âš ï¸ [PERF] Slow routing: {total_time:.0f}ms")
        
        # Step 4: Route based on intent
        # ğŸ”¥ UNIFIED ARCHITECTURE REFACTOR (Phase 7)
        # Force ALL traffic to Agent. Deprecated S2S path.
        
        # å¤æ‚æŸ¥è¯¢ï¼šæ‹¦æˆª S2Sï¼Œå¯åŠ¨ Agent
        self.current_path = "agent"
        print(f"â” [ROUTER] '{resolved_text}' â†’ AGENT (Unified Path)")
        logger.info(f"ğŸ”€ [ROUTER] '{resolved_text}' â†’ AGENT (Unified Path)")
        
        # Speak transitional phrase for better UX (only if complexity detected, otherwise silent)
        # For unified path, we might want to skip transitions for simple "hello" to be faster
        if intents and "conversation" not in intents:
             await self._speak_transition(intents[0])
        
        # å¼‚æ­¥å¤„ç† Agent è·¯å¾„
        asyncio.create_task(self._handle_agent_path(resolved_text, intents))
        
        # Step 5: Update context for next query
        if self.context_resolver:
            self.context_resolver.update_context(resolved_text, "agent")
    
    async def _speak_transition(self, intent: str):
        """
        Speak transitional phrase for better UX during long operations.
        
        Args:
            intent: Detected intent (e.g., "weather", "stock")
        """
        phrase = TRANSITION_PHRASES.get(intent, TRANSITION_PHRASES["default"])
        
        try:
            # Use quick TTS (non-blocking, fire-and-forget)
            if hasattr(self.jarvis, '_speak_quick'):
                await self.jarvis._speak_quick(phrase)
            else:
                # Fallback: log only
                logger.info(f"ğŸ’¬ [TRANSITION] Would say: {phrase}")
        except Exception as e:
            # Don't fail routing if transition fails
            logger.debug(f"[TRANSITION] Failed to speak: {e}")
    
    async def _handle_agent_path(self, transcription: str, intents: List[str] = None):
        """
        å¤„ç† Agent è·¯å¾„
        
        Args:
            transcription: Resolved query text
            intents: List of detected intents (for multi-intent queries)
        """
        try:
            # 1. æ‹¦æˆª S2S éŸ³é¢‘
            await self.suppress_s2s_audio()
            
            # 2. è°ƒç”¨ Agent (ä½¿ç”¨ HybridJarvis å·²ç»åˆå§‹åŒ–å¥½çš„ brain)
            async with self._agent_lock:
                print(f"ğŸ§  [ROUTER] Calling Agent for: {transcription}")
                if intents:
                    print(f"   Intents: {intents}")
                logger.info(f"ğŸ§  [AGENT] Processing: {transcription}")
                
                # Streaming Callback Wrapper
                async def on_token(token: str):
                    # Route to HybridJarvis streaming TTS handler
                    if hasattr(self.jarvis, '_speak_stream'):
                        await self.jarvis._speak_stream(token, is_final=False)
                
                # Call agent with streaming callback
                response = await self.jarvis.brain.run(transcription, stream_callback=on_token)
                
                # Flush any remaining buffer
                if hasattr(self.jarvis, '_speak_stream'):
                    await self.jarvis._speak_stream("", is_final=True)
                    
                print(f"ğŸ’¬ [ROUTER] Agent Response: {response[:50]}...")
                logger.info(f"ğŸ’¬ [AGENT] Response: {response[:50]}...")
            
            # 3. Use Bidirection TTS æ’­æ”¾å“åº” (Fallback if streaming failed/not used)
            # If streaming was used, this might be redundant, but _speak_v3 handles full text.
            # However, since we streamed it, we shouldn't speak it again!
            # BUT: If agent logic used tools and returned a final string WITHOUT streaming (e.g. tools don't stream),
            # we need to speak it.
            # Logic: If streaming happened, response was spoken. If not (e.g. tool result), we need to speak.
            # Since `agent.run` now supports mixed modes, we should check if we should speak the final result.
            # Best way: Rely on `on_token` to have spoken conversation. 
            # If `response` is just the final text, and we streamed it...
            pass # We streamed it! Don't speak again to avoid echo.
            
            print("âœ… [ROUTER] Agent Path completed")
            
        except Exception as e:
            logger.error(f"âŒ [AGENT PATH] Error: {e}", exc_info=True)
            # é™çº§åˆ° S2S
            self.current_path = "s2s"
    
    async def suppress_s2s_audio(self):
        """æ‹¦æˆª S2S éŸ³é¢‘è¾“å‡º"""
        logger.info("ğŸ”‡ [ROUTER] Suppressing S2S audio")
        
        # æ¸…ç©º speaker_queue
        if hasattr(self.jarvis, 'speaker_queue'):
            while not self.jarvis.speaker_queue.empty():
                try:
                    self.jarvis.speaker_queue.get_nowait()
                except:
                    break
        
        # è®¾ç½®é™éŸ³æ ‡å¿— (æ§åˆ¶æ’­æ”¾)
        self.jarvis.skip_cloud_response = True
        # åŒæ—¶è®¾ç½®å›å£°æ¶ˆé™¤æ ‡å¿— (æ§åˆ¶éº¦å…‹é£)
        self.jarvis.self_speaking_mute = True
    
    async def speak_with_tts(self, text: str):
        """ä½¿ç”¨ HybridJarvis çš„ _speak_v3 æ’­æ”¾æ–‡æœ¬ (ç»Ÿä¸€ä½¿ç”¨å·²éªŒè¯å·¥ä½œçš„è·¯å¾„)"""
        logger.info(f"ğŸ”Š [TTS] Redirecting to _speak_v3: {text[:50]}...")
        
        try:
            # ç›´æ¥è°ƒç”¨ jarvis çš„ _speak_v3
            # è¿™ä¼šè‡ªåŠ¨å¤„ç† "agent" æ ‡ç­¾å’Œæ­£ç¡®çš„ V1 Binary åè®®
            # æ³¨æ„ï¼š_speak_v3 æ˜¯å¼‚æ­¥ç”Ÿæˆå¤šæ®µéŸ³é¢‘çš„ï¼Œä½†ç”±äºå®ƒå†…éƒ¨æ˜¯å¼‚æ­¥å¾ªç¯ï¼Œæˆ‘ä»¬éœ€è¦ await å®ƒ
            await self.jarvis._speak_v3(text)
            
            logger.info("âœ… [TTS] Playback complete via _speak_v3")
            
        except Exception as e:
            logger.error(f"âŒ [TTS] Error in _speak_v3 handoff: {e}", exc_info=True)
        finally:
            # âœ… CRITICAL: Reset flags in finally block (per SKILL.md)
            # This ensures cleanup even if exceptions occur
            self.jarvis.self_speaking_mute = False
            self.jarvis.skip_cloud_response = False
            self.current_path = None
    
    def should_suppress_s2s(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥æ‹¦æˆª S2S éŸ³é¢‘"""
        return self.current_path == "agent"
