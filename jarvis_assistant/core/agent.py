"""
Jarvis Agent Core
Autonomous agent with planning, execution, and verification loop.
"""

import asyncio
import json
import os
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, field
from enum import Enum
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

from jarvis_assistant.core.memory import get_memory
from jarvis_assistant.core.intent_matcher import IntentMatcher
from jarvis_assistant.services.tools import get_all_tools


class StepStatus(Enum):
    PENDING = "pending"
    RUNNING = "running"
    SUCCESS = "success"
    FAILED = "failed"
    RETRYING = "retrying"


@dataclass
class PlanStep:
    """A single step in an execution plan"""
    description: str
    tool_name: Optional[str] = None
    tool_args: Dict[str, Any] = field(default_factory=dict)
    status: StepStatus = StepStatus.PENDING
    result: Optional[str] = None
    error: Optional[str] = None
    retry_count: int = 0


@dataclass
class ExecutionPlan:
    """Multi-step execution plan"""
    task: str
    steps: List[PlanStep] = field(default_factory=list)
    final_result: Optional[str] = None
    success: bool = False


class JarvisAgent:
    """
    Autonomous Jarvis Agent with:
    - Task planning and decomposition
    - Multi-step tool execution
    - Self-correction on failures
    - Persistent memory
    """
    
    MAX_RETRIES = 2
    
    def __init__(self):
        print("ğŸ¤– Initializing Jarvis Agent...")
        self.memory = get_memory()
        
        # Add semantic memory capabilities
        from jarvis_assistant.core.semantic_memory import enhance_memory
        self.semantic_memory = enhance_memory(self.memory)
        
        # Use plugin manager for dynamic tool loading
        from jarvis_assistant.utils import get_plugin_manager
        plugin_mgr = get_plugin_manager()
        self.tools = plugin_mgr.loaded_plugins

        # Add feedback manager (Phase 5)
        from jarvis_assistant.core.feedback_manager import get_feedback_manager # Wait, where is feedback_manager?
        self.feedback = get_feedback_manager()
        
        print(f"ğŸ”§ Loaded {len(self.tools)} tools via plugin manager")
        
        # Intent to tool mapping for quick routing
        self.intent_keywords = {
            "å¤©æ°”": "get_weather",
            "å‡ ç‚¹": "get_current_time",
            "æ—¶é—´": "get_current_time",
            "è®¡ç®—": "calculate",
            "æ’­æ”¾": "play_music",
            "éŸ³ä¹": "play_music",
            "åœæ­¢": "play_music",
            "å¼€ç¯": "control_xiaomi_light",
            "å…³ç¯": "control_xiaomi_light",
            "è¯»å–æ–‡ä»¶": "read_file",
            "å†™å…¥æ–‡ä»¶": "write_file",
            "æŸ¥çœ‹ç›®å½•": "list_dir",
            "å‘é‚®ä»¶": "send_email",
            "å†™é‚®ä»¶": "send_email",
            "æŸ¥çœ‹é‚®ä»¶": "list_emails",
            "æ”¶ä»¶ç®±": "list_emails",
            "æ·»åŠ æ—¥ç¨‹": "add_calendar_event",
            "å®‰æ’æ—¥ç¨‹": "add_calendar_event",
            "æŸ¥çœ‹æ—¥ç¨‹": "list_calendar_events",
            "æ—¥å†": "list_calendar_events",
            "æé†’": "schedule_reminder",
            # News & Stocks
            "æ–°é—»": "get_news",
            "å¤´æ¡": "get_news",
            "çƒ­ç‚¹": "get_news",
            "è‚¡ä»·": "get_stock_price",
            "å¸ä»·": "get_stock_price",
            "è¡Œæƒ…": "get_stock_price",
            "èµ°åŠ¿": "get_stock_price",
            "ä»·æ ¼": "get_stock_price",
            # Web search (explicit)
            "æœç´¢": "web_search",
            # Feedback
            "ä¸å¯¹": "feedback_negative", # New intent for feedback
            "é”™äº†": "feedback_negative",
            "ä¸æ˜¯": "feedback_negative",
            "å¾ˆå¥½": "feedback_positive",
        }
        
        # Initialize Scheduler
        from jarvis_assistant.core.scheduler import get_scheduler
        self.scheduler = get_scheduler()
        self.scheduler.set_callback(self.handle_trigger)
        
        import asyncio
        try:
            loop = asyncio.get_running_loop()
            loop.create_task(self.scheduler.start())
        except RuntimeError:
            pass 

    async def handle_trigger(self, prompt: str):
        # ... existing code ...
        print(f"âš¡ Proactive Trigger: {prompt}")
        await self.run(prompt)
    
    async def run(self, user_input: str, stream_callback: Optional[callable] = None) -> str:
        """
        Main agent loop with Self-Learning
        """
        # ğŸµ Auto-pause music when user speaks (to prevent overlap with Jarvis response)
        music_tool = self.tools.get("play_music")
        if music_tool and hasattr(music_tool, '_current_process') and music_tool._current_process:
            try:
                print("ğŸ”‡ Pausing background music...")
                music_tool._current_process.terminate()
                music_tool._current_process = None
            except:
                pass
        
        # Check for feedback keywords first
        if user_input in ["ä¸å¯¹", "é”™äº†", "ä¸æ˜¯è¿™ä¸ª", "wrong", "stop"]:
             return await self.handle_user_feedback("negative", user_input)
             
        # Store user input
        self.memory.add_conversation("user", user_input)
        
        try:
            # 1. Plan (with learning)
            plan = await self.plan(user_input)
            
            # Check advice from feedback manager
            advice = self.feedback.get_advice(user_input)
            if advice:
                print(f"ğŸ§  Learning recall: {'; '.join(advice)}")
                # TODO: Re-plan if heavy warning? For now just log.
            
            print(f"ğŸ“‹ Plan created: {len(plan.steps)} steps")
            
            # ... execution loop ...
            for i, step in enumerate(plan.steps):
                print(f"ğŸ”„ Step {i+1}/{len(plan.steps)}: {step.description}")
                step.status = StepStatus.RUNNING
                
                result = await self.execute_step(step, stream_callback)
                
                if step.status == StepStatus.FAILED and step.retry_count < self.MAX_RETRIES:
                     # ... retry logic ...
                     print(f"âš ï¸ Step failed, retrying... ({step.retry_count + 1}/{self.MAX_RETRIES})")
                     step.retry_count += 1
                     step.status = StepStatus.RETRYING
                     result = await self.execute_step(step)
            
            # 3. Synthesize result
            final_result = self.synthesize(plan)
            plan.final_result = final_result
            plan.success = all(s.status == StepStatus.SUCCESS for s in plan.steps)
            
            # Store result in memory
            self.memory.add_conversation("assistant", final_result)
            self.memory.add_task(
                task=user_input,
                steps=[s.description for s in plan.steps],
                result=final_result,
                success=plan.success
            )
            
            # ğŸ”¥ Active Memory Extraction (éé˜»å¡)
            asyncio.create_task(self._extract_memories(user_input, final_result))
            
            return final_result
            
        except Exception as e:
            error_msg = f"Agent error: {str(e)}"
            print(f"âŒ {error_msg}")
            self.memory.add_conversation("assistant", error_msg, {"error": True})
            return error_msg
    
    async def handle_user_feedback(self, type: str, comment: str) -> str:
        """Handle explicit user feedback"""
        # Get last task from memory
        last_task = self.memory.task_history[-1] if self.memory.task_history else None
        
        if last_task:
            task_query = last_task.get("task", "unknown")
            steps = last_task.get("steps", [])
            # Assume last tool used
            last_tool = steps[-1] if steps else "unknown"
            
            self.feedback.record_feedback(task_query, last_tool, type, comment)
            return f"ğŸ™ {type.title()} feedback recorded. I will learn from this."
        else:
            return "??? No recent task to learn from."
    
    async def _extract_memories(self, user_input: str, assistant_response: str) -> None:
        """
        æå–å¹¶ä¿å­˜ç”¨æˆ·ä¿¡æ¯ï¼ˆå¼‚æ­¥ï¼Œéé˜»å¡ï¼‰
        """
        try:
            from jarvis_assistant.core.memory_agent import get_memory_agent
            agent = get_memory_agent()
            await agent.analyze_and_extract(user_input, assistant_response)
        except Exception as e:
            # Silent fail - memory extraction should not break main flow
            print(f"âš ï¸ Memory extraction error: {e}")
    


    async def plan(self, user_input: str) -> ExecutionPlan:
        """
        Decompose user input into executable steps using LLM.
        Upgraded from keyword matching to intelligent planning.
        """
        plan = ExecutionPlan(task=user_input)
        
        # Build planning prompt with available tools and context
        history = self.get_history(limit=5)
        
        # ğŸ”¥ Get User Context (Hierarchical)
        context = self.memory.get_context_for_response()
        context_lines = []
        if context:
            if "project" in context:
                context_lines.append(f"**Current Project**: {context['project']}")
            if "learning" in context:
                context_lines.append(f"**Learning Focus**: {context['learning']}")
            if "research_area" in context:
                context_lines.append(f"**Research Area**: {context['research_area']}")
            if "location" in context:
                context_lines.append(f"**Location**: {context['location']}")
            if "name" in context:
                context_lines.append(f"**Name**: {context['name']}")
        
        context_str = "\n".join(context_lines) if context_lines else "æš‚æ— ç”¨æˆ·èƒŒæ™¯ä¿¡æ¯"
        
        tool_descriptions = "\n".join([
            f"- {name}: {tool.description}" 
            for name, tool in list(self.tools.items())[:20]
        ])
        
        planning_prompt = f"""You are Jarvis, a warm and intelligent assistant who truly knows the user.

[USER CONTEXT] (Use this background to personalize your responses)
{context_str}

**Personalization Guidelines**:
1. When answering questions, naturally use the user's background as examples when relevant
2. If the topic relates to their project/research, acknowledge the connection
3. Use a friendly, conversational tone (åƒæœ‹å‹ä¸€æ ·ï¼Œä¸è¦ç”¨"æ‚¨")
4. Don't mechanically repeat user info - weave it naturally into responses
5. Occasionally (not every time) show care about their ongoing projects

[CONVERSATION HISTORY]
{history}

[AVAILABLE TOOLS]
{tool_descriptions}

[USER REQUEST]
"{user_input}"

[INSTRUCTIONS]
1. Analyze if the user request requires tool usage based on history and intent.
2. If the user mentions updating their info (location, name, etc), use 'update_user_info'.
3. If user mentions a project/research/learning focus, it will be automatically saved.
4. For weather/location queries, prioritize the user's location from [USER CONTEXT] if no city is specified.
5. If tools are needed, respond with a JSON object containing the steps.
6. If it's a simple conversational response, return: {{"steps": []}}.

Response (JSON only):"""
        
        try:
            # Use simple keyword fallback first (fast path)
            matched_tools = []
            
            # --- CUSTOM INTENT KEYWORDS ---
            # Extend default intent matcher with user tools
            import re
            # Match "æˆ‘åœ¨é’å²›å¸‚" or "æˆ‘ç°åœ¨åœ¨é’å²›" or "å»é’å²›"
            # Captures "é’å²›" from "åœ¨é’å²›å¸‚"
            loc_match = re.search(r"(?:æˆ‘åœ¨|åœ¨|å»)(.+?)[å¸‚åŒºå¿]", user_input)
            if loc_match:
                 city = loc_match.group(1).replace("ç°åœ¨", "").replace("åœ¨", "").strip()
                 print(f"ğŸš€ Fast Path: User Location Update -> {city}")
                 matched_tools.append(("update_user_info", {"key": "location", "value": city}))

            for keyword, tool_name in self.intent_keywords.items():
                if keyword in user_input:
                    # Special handling for weather without city
                    if tool_name == "get_weather":
                         # Check if city in input
                         # Simple check: if input length < 10 ("ä»Šå¤©å¤©æ°”") -> use profile
                         if len(user_input) < 10 and "å¤©æ°”" in user_input:
                             profile_city = self.memory.get_profile("location")
                             if profile_city:
                                 matched_tools.append((tool_name, {"city": profile_city}))
                                 continue
                    
                    matched_tools.append((tool_name, {}))
            
            if matched_tools:
                # Fast keyword-based path
                for tool_name, forced_args in matched_tools:
                    tool_args = self._extract_args(user_input, tool_name)
                    tool_args.update(forced_args)  # ğŸ”¥ Apply profile args if any
                    
                    # ğŸ”´ FIX #2: Handle multi-symbol stock queries
                    if tool_name == "get_stock_price" and "symbol" in tool_args:
                        symbols = tool_args["symbol"].split(",") if "," in tool_args["symbol"] else [tool_args["symbol"]]
                        for symbol in symbols:
                            step = PlanStep(
                                description=f"Execute {tool_name} for {symbol.strip()}",
                                tool_name=tool_name,
                                tool_args={"symbol": symbol.strip()}
                            )
                            plan.steps.append(step)
                    else:
                        # Single-step tool
                        step = PlanStep(
                            description=f"Execute {tool_name}",
                            tool_name=tool_name,
                            tool_args=tool_args
                        )
                        plan.steps.append(step)
            else:
                # No keyword match - try heuristic intent inference
                inferred = self._infer_intent(user_input)
                if inferred:
                    tool_name, tool_args = inferred
                    plan.steps.append(PlanStep(
                        description=f"Execute {tool_name}",
                        tool_name=tool_name,
                        tool_args=tool_args
                    ))
                else:
                    # ğŸ”´ FAST PATH: Context continuation detection (skip Doubao for lower latency)
                    context_inferred = self._infer_from_context(user_input)
                    if context_inferred:
                        tool_name, tool_args = context_inferred
                        print(f"ğŸš€ Context shortcut: {tool_name}")
                        plan.steps.append(PlanStep(
                            description=f"Execute {tool_name} (context)",
                            tool_name=tool_name,
                            tool_args=tool_args
                        ))
                    else:
                        # ğŸš€ FAST PATH: Detect pure conversational queries (no tools needed)
                        conversational_patterns = [
                            "è®°ä½", "è®°å¾—", "æˆ‘å–œæ¬¢", "æˆ‘æƒ³", "è§£é‡Š", "ä»€ä¹ˆæ˜¯", "ä¸ºä»€ä¹ˆ", 
                            "æ€ä¹ˆæ ·", "å¦‚ä½•", "å‘Šè¯‰æˆ‘", "ä½ è§‰å¾—", "ä½ è®¤ä¸º", "èŠèŠ"
                        ]
                        is_conversational = any(p in user_input for p in conversational_patterns)
                        
                        if is_conversational and len(user_input) < 50:
                            # Skip expensive Planner for obvious conversational queries
                            print("ğŸ’¬ Conversational query detected - skipping Planner")
                            plan.steps.append(PlanStep(
                                description="Respond conversationally",
                                tool_name=None
                            ))
                        else:
                            # Complex query - engage Doubao Planner
                            print("ğŸ§  No keyword match. Engaging Cognitive Brain (Doubao)...")
                            llm_plan = await self._plan_with_doubao(user_input, planning_prompt)
                        
                        if llm_plan and llm_plan.get("steps"):
                            for s in llm_plan["steps"]:
                                plan.steps.append(PlanStep(
                                    description=s.get("description", "LLM Task"),
                                    tool_name=s.get("tool"),
                                    tool_args=s.get("args", {})
                                ))
                        else:
                            # Fallback
                            plan.steps.append(PlanStep(
                                description="Respond conversationally",
                                tool_name=None
                            ))
            
        except Exception as e:
            print(f"Planning error: {e}")
            plan.steps.append(PlanStep(
                description="Fallback: conversational response",
                tool_name=None
            ))
        
        return plan

    async def _plan_with_doubao(self, user_input: str, system_prompt: str) -> dict:
        """
        Call Doubao (Volcengine) HTTP API for planning using aiohttp for non-blocking IO.
        """
        import aiohttp
        import json
        import os
        
        api_key = os.getenv("DOUBAO_ARK_API_KEY")
        endpoint_id = os.getenv("DOUBAO_ENDPOINT_ID")
        
        if not api_key or not endpoint_id:
            print("âš ï¸ Missing Doubao API Key or Endpoint ID for HTTP Planner.")
            return None
            
        url = "https://ark.cn-beijing.volces.com/api/v3/chat/completions"
        
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        
        payload = {
            "model": endpoint_id,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_input}
            ],
            "response_format": {"type": "json_object"}
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                # ğŸš€ Flash model needs more time for complex planning (increased from 30s)
                async with session.post(url, headers=headers, json=payload, timeout=45) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        print("âœ… Doubao Planner Respond Success")
                        content = data['choices'][0]['message']['content']
                        if isinstance(content, str):
                            return json.loads(content)
                        return content
                    else:
                        text = await resp.text()
                        print(f"âŒ Doubao HTTP Error: {text}")
                        return None
        except Exception as e:
            print(f"âŒ Doubao Connection Error: {e}")
            return None

    def _infer_from_context(self, user_input: str) -> Optional[tuple]:
        """
        ğŸš€ FAST PATH: Infer intent from conversation context without calling LLM.
        Used for follow-up queries like "é‚£æ˜å¤©å‘¢ï¼Ÿ" or "æ¢ä¸€é¦–"
        """
        import re
        text = user_input.strip()
        
        # Pattern 1: Time-based follow-up (æ˜å¤©ã€åå¤©ã€æ˜¨å¤©)
        time_patterns = ["æ˜å¤©", "åå¤©", "æ˜¨å¤©", "ä¸‹å‘¨", "è¿™å‘¨", "å‘¨æœ«"]
        if any(t in text for t in time_patterns) or text in ["é‚£æ˜å¤©å‘¢", "é‚£åå¤©å‘¢", "é‚£å‘¢"]:
            # Check last conversation topic
            last_topic = self._get_last_topic()
            if last_topic == "weather":
                city = self._get_last_city() or "Beijing"
                # ğŸ”§ FIX: Use get_forecast for future dates, not get_weather
                if "æ˜å¤©" in text:
                    return ("get_forecast", {"city": city, "days": 2})  # Today + Tomorrow
                elif "åå¤©" in text:
                    return ("get_forecast", {"city": city, "days": 3})  # Today + 2 days
                else:
                    return ("get_weather", {"city": city})
            elif last_topic == "stock":
                # Stock doesn't have "tomorrow" - just repeat query
                return ("get_stock_price", {"symbol": self._get_last_symbol() or "AAPL"})
        
        # Pattern 2: Music follow-up (æ¢ä¸€é¦–ã€ä¸‹ä¸€é¦–ã€ä¸Šä¸€é¦–)
        music_patterns = ["æ¢ä¸€é¦–", "ä¸‹ä¸€é¦–", "ä¸Šä¸€é¦–", "ç»§ç»­æ’­æ”¾", "åœ"]
        for p in music_patterns:
            if p in text:
                if "åœ" in text:
                    return ("play_music", {"action": "stop"})
                else:
                    return ("play_music", {"action": "play"})  # Random next
        
        # Pattern 3: Generic "å‘¢" follow-up
        if text.endswith("å‘¢") or text.endswith("å‘¢ï¼Ÿ"):
            last_topic = self._get_last_topic()
            if last_topic:
                # Reuse last tool with same args
                last_args = self._get_last_args()
                if last_topic == "weather":
                    return ("get_weather", last_args or {"city": "Beijing"})
                elif last_topic == "stock":
                    return ("get_stock_price", last_args or {"symbol": "AAPL"})
        
        return None
    
    def _get_last_topic(self) -> Optional[str]:
        """Get the topic of the last conversation turn"""
        if not self.memory.task_history:
            return None
        last_task = self.memory.task_history[-1]
        steps = last_task.get("steps", [])
        for step in steps:
            if "weather" in step.lower():
                return "weather"
            if "stock" in step.lower():
                return "stock"
            if "music" in step.lower():
                return "music"
        return None
    
    def _get_last_city(self) -> Optional[str]:
        """Extract city from last weather query"""
        if not self.memory.conversations:
            return None
        for msg in reversed(self.memory.conversations):
            if msg.get("role") == "assistant":
                content = msg.get("content", "")
                # Extract city from response like "åŒ—äº¬å¤©æ°”ï¼š..."
                import re
                match = re.search(r'([^\s]+)å¤©æ°”', content)
                if match:
                    return match.group(1)
        return None
    
    def _get_last_symbol(self) -> Optional[str]:
        """Extract stock symbol from last query"""
        if not self.memory.conversations:
            return None
        for msg in reversed(self.memory.conversations):
            if msg.get("role") == "assistant":
                content = msg.get("content", "")
                import re
                match = re.search(r'ï¼ˆ([A-Z]+)ï¼‰', content)
                if match:
                    return match.group(1)
        return None
    
    def _get_last_args(self) -> Optional[dict]:
        """Get args from last successful tool call"""
        if not self.memory.task_history:
            return None
        last_task = self.memory.task_history[-1]
        # Simple extraction - could be improved
        return None
    
    def _infer_intent(self, user_input: str) -> Optional[tuple]:
        """Heuristic intent inference when no explicit keyword match exists."""
        import re
        text = user_input.strip()
        t = text.lower()
        scores = {}

        def add(tool: str, pts: int):
            if tool in self.tools:
                scores[tool] = scores.get(tool, 0) + pts

        is_question = any(x in text for x in ["?", "ï¼Ÿ", "å—", "ä¹ˆ", "å‡ ", "å¤šå°‘", "è¦ä¸è¦", "ä¼šä¸ä¼š"])

        # Math
        if re.search(r'[\d\.]+\s*[\+\-\*\/]\s*[\d\.]+', text) or any(op in text for op in ["åŠ ", "å‡", "ä¹˜", "é™¤"]):
            add("calculate", 3)

        # Time
        if any(x in text for x in ["å‡ ç‚¹", "å‡ æ—¶", "å‡ ç‚¹é’Ÿ", "å‡ ç‚¹äº†", "ç°åœ¨å‡ ç‚¹", "æ—¶é—´", "ç°åœ¨æ˜¯ä»€ä¹ˆæ—¶å€™", "æ˜ŸæœŸå‡ ", "æ—¥æœŸ"]):
            add("get_current_time", 3)

        # Reminders
        if "æé†’" in text or re.search(r'\d+\s*(ç§’|åˆ†é’Ÿ|åˆ†|å°æ—¶|æ—¶)å', text):
            add("schedule_reminder", 3)

        # Weather
        weather_cues = ["å¤©æ°”", "æ°”æ¸©", "æ¸©åº¦", "å†·", "çƒ­", "ä¸‹é›¨", "é›¨", "é›ª", "åˆ®é£", "é£å¤§", "é›¾", "éœ¾", "æ½®æ¹¿", "æ¹¿åº¦", "å¤–é¢", "å‡ºé—¨", "å¸¦ä¼", "ä½“æ„Ÿ", "ç©ºæ°”è´¨é‡", "ç©¿ä»€ä¹ˆ"]
        if any(c in text for c in weather_cues):
            add("get_weather", 2 if is_question else 1)
        if re.search(r'(å‡ åº¦|å¤šå°‘åº¦|\d+\s*åº¦|\d+\s*Â°)', text):
            add("get_weather", 2)

        # Thermostat
        thermo_cues = ["ç©ºè°ƒ", "æš–æ°”", "åˆ¶å†·", "åˆ¶çƒ­", "è°ƒåˆ°", "è°ƒæ¸©", "å‡æ¸©", "é™æ¸©", "é£é€Ÿ", "çƒ­ä¸€ç‚¹", "å†·ä¸€ç‚¹"]
        if any(c in text for c in thermo_cues):
            add("control_thermostat", 3)

        # Lights (explicit on/off)
        if any(c in text for c in ["å¼€ç¯", "æ‰“å¼€ç¯", "å…³ç¯", "å…³æ‰ç¯", "æŠŠç¯æ‰“å¼€", "æŠŠç¯å…³ä¸Š", "äº®ä¸€ç‚¹", "æš—ä¸€ç‚¹"]):
            add("control_xiaomi_light", 3)

        # Music
        music_cues = ["éŸ³ä¹", "æ­Œæ›²", "æ­Œ", "æ’­æ”¾", "æ¥é¦–", "æ¥ç‚¹", "å¬ç‚¹", "æ”¾ç‚¹", "æƒ³å¬", "ç‚¹ä¸€é¦–"]
        if any(c in text for c in music_cues):
            add("play_music", 2)

        # News
        news_cues = ["æ–°é—»", "å¤´æ¡", "çƒ­ç‚¹", "è¦é—»", "æœ€æ–°æ¶ˆæ¯", "å‘ç”Ÿäº†ä»€ä¹ˆ", "æœ‰ä»€ä¹ˆå¤§äº‹", "å¿«è®¯", "ç®€æŠ¥"]
        if any(c in text for c in news_cues):
            add("get_news", 2)

        # Stock/Crypto
        ticker_whitelist = {
            "nvda", "nvidia", "tsla", "tesla", "aapl", "apple", "msft", "microsoft",
            "baba", "alibaba", "tencent", "0700", "qqq", "spy", "btc", "eth", "amzn",
            "amazon", "meta", "goog", "googl", "google"
        }
        tokens = re.findall(r'\b[a-zA-Z0-9]{2,6}(?:-[a-zA-Z]{1,3})?\b', text)
        for tok in tokens:
            if tok.lower() in ticker_whitelist:
                add("get_stock_price", 3)
                break
        company_cues = ["è‹±ä¼Ÿè¾¾", "è‹±ä¼Ÿ", "ç‰¹æ–¯æ‹‰", "ç‰¹æ–¯", "è‹¹æœ", "å¾®è½¯", "é˜¿é‡Œ", "è…¾è®¯", "èŒ…å°", "æ¯”ç‰¹å¸", "ä»¥å¤ªåŠ", "ç™¾åº¦", "äº¬ä¸œ", "æ‹¼å¤šå¤š", "ç¾å›¢", "å°ç±³"]
        if any(c in text for c in company_cues):
            add("get_stock_price", 2)
        stock_cues = ["è‚¡ä»·", "è‚¡ç¥¨", "è‚¡å¸‚", "å¤§ç›˜", "æ¶¨è·Œ", "è¡Œæƒ…", "èµ°åŠ¿", "å¸ä»·", "æ•°å­—è´§å¸", "å¸", "å¸‚å€¼"]
        if any(c in text for c in stock_cues):
            add("get_stock_price", 2)

        # Web search (lowest priority)
        search_cues = ["æœç´¢", "æœä¸€ä¸‹", "æŸ¥ä¸€ä¸‹", "å¸®æˆ‘æŸ¥", "å¸®æˆ‘æ‰¾", "èµ„æ–™", "ç™¾ç§‘", "æ˜¯è°", "æ˜¯ä»€ä¹ˆ", "æ€ä¹ˆ", "ä¸ºä»€ä¹ˆ", "æ•™ç¨‹", "å®˜ç½‘", "åœ°å€"]
        if any(c in text for c in search_cues):
            add("web_search", 1)

        if not scores:
            return None

        tool_name = max(scores.items(), key=lambda kv: kv[1])[0]
        if scores[tool_name] < 2 and tool_name != "web_search":
            return None

        return tool_name, self._extract_args(user_input, tool_name)
    
    def _extract_args(self, user_input: str, tool_name: str) -> Dict[str, Any]:
        """Extract tool arguments from user input"""
        args = {}
        
        if tool_name == "get_weather":
            # flexible extraction: "æŸ¥è¯¢[city]çš„å¤©æ°”"
            import re
            city = None
            
            # ğŸ”´ FIX #3: Don't extract time words as locations
            time_words = ["ä»Šå¤©", "æ˜å¤©", "åå¤©", "æ˜¨å¤©", "æ™šä¸Š", "ä¸­åˆ", "æ—©ä¸Š", "ä¸‹åˆ", "å‚æ™š"]
            
            match = re.search(r'(?:æŸ¥è¯¢|æŸ¥çœ‹|è·å–)?(.+?)çš„?å¤©[æ°”å€™]', user_input)
            if match:
                city_candidate = match.group(1).strip()
                # Clean up strict prefixes if user said "æŸ¥è¯¢åŒ—äº¬å¤©æ°”" -> "åŒ—äº¬"
                for prefix in ["æŸ¥è¯¢", "æŸ¥çœ‹", "è·å–"]:
                    if city_candidate.startswith(prefix):
                        city_candidate = city_candidate[len(prefix):]
                
                # ğŸ”´ CRITICAL: Don't use time words as city names
                if city_candidate not in time_words:
                    city = city_candidate
            
            if not city:
                # Heuristic fallback (handles "å¤–é¢å†·å—", "ä¸Šæµ·å¤šå°‘åº¦" etc.)
                city = IntentMatcher.match_weather(user_input)
                if city in time_words:
                    city = None
            
            # ğŸ”´ FIX #3: Default to None (tool has Beijing default)
            args["city"] = city or None
        
        elif tool_name == "calculate":
            # Extract expression (support Chinese operators)
            import re
            expr = user_input.replace("ä¹˜ä»¥", "*").replace("ä¹˜", "*")
            expr = expr.replace("é™¤ä»¥", "/").replace("é™¤", "/")
            expr = expr.replace("åŠ ", "+").replace("å‡", "-")
            match = re.search(r'[\d\+\-\*\/\(\)\.]+', expr)
            if match:
                args["expression"] = match.group().strip()

        elif tool_name == "get_stock_price":
            import re
            
            # ğŸ”´ FIX #1: Multi-entity detection for "Xå’ŒY", "Xä»¥åŠY", "Xè·ŸY"
            text = user_input
            symbols = []
            
            # Company name to symbol mapping
            company_map = {
                "ç‰¹æ–¯æ‹‰": "TSLA", "è‹¹æœ": "AAPL", "å¾®è½¯": "MSFT", 
                "è‹±ä¼Ÿè¾¾": "NVDA", "äºšé©¬é€Š": "AMZN", "è°·æ­Œ": "GOOG",
                "é˜¿é‡Œ": "BABA", "è…¾è®¯": "0700.HK", "èŒ…å°": "600519.SS",
                "æ¯”ç‰¹å¸": "BTC-USD", "ä»¥å¤ªåŠ": "ETH-USD", "é»„é‡‘": "GC=F"
            }
            
            # Pattern 1: "Xå’ŒY" compound queries
            compound_pattern = r'([^\sï¼Œ,ã€‚.]+?)(?:å’Œ|ä»¥åŠ|è·Ÿ|ä¸)([^\sï¼Œ,ã€‚.]+)'
            match = re.search(compound_pattern, text)
            if match:
                entity1 = match.group(1).strip()
                entity2 = match.group(2).strip()
                
                # Clean up: remove "æŸ¥è¯¢", "çš„è‚¡ä»·" etc.
                for prefix in ["æŸ¥è¯¢", "æŸ¥çœ‹", "è·å–"]:
                    entity1 = entity1.replace(prefix, "").strip()
                    entity2 = entity2.replace(prefix, "").strip()
                for suffix in ["è‚¡ä»·", "çš„è‚¡ä»·", "çš„", "ä»·æ ¼", "è¡Œæƒ…"]:
                    entity1 = entity1.replace(suffix, "").strip()
                    entity2 = entity2.replace(suffix, "").strip()
                
                # Map to symbols
                symbol1 = company_map.get(entity1, entity1.upper() if re.match(r'^[A-Z]{1,5}$', entity1.upper()) else entity1)
                symbol2 = company_map.get(entity2, entity2.upper() if re.match(r'^[A-Z]{1,5}$', entity2.upper()) else entity2)
                
                symbols = [symbol1, symbol2]
            else:
                # Pattern 2: Try to extract ticker (e.g., NVDA, BRK-B)
                m = re.search(r'\b[a-zA-Z]{1,6}(?:-[a-zA-Z]{1,3})?\b', user_input)
                if m:
                    symbols = [m.group(0).upper()]
                else:
                    # Pattern 3: Company name extraction
                    q = user_input
                    for w in ["è‚¡ä»·", "å¸ä»·", "è¡Œæƒ…", "èµ°åŠ¿", "ä»·æ ¼", "æŸ¥è¯¢", "æŸ¥çœ‹", "ç°åœ¨", "æœ€æ–°", "å¤šå°‘", "æ€ä¹ˆæ ·", "å¦‚ä½•", "å’‹æ ·", "æƒ…å†µ", "çš„"]:
                        q = q.replace(w, "")
                    q = q.strip()
                    
                    # Check if it's a known company
                    symbol = company_map.get(q, q.upper() if q else user_input.strip())
                    symbols = [symbol]
            
            # Store as comma-separated if multiple
            args["symbol"] = symbols[0] if len(symbols) == 1 else ",".join(symbols)

        elif tool_name == "get_news":
            # Determine category
            category = "world"
            if any(k in user_input for k in ["è´¢ç»", "é‡‘è", "è‚¡å¸‚", "å•†ä¸š", "finance", "business"]):
                category = "finance"
            args["category"] = category

        elif tool_name == "web_search":
            args["query"] = IntentMatcher.match_web_search(user_input)
            args["num_results"] = 3
        
        elif tool_name == "play_music":
            action, query = IntentMatcher.match_music(user_input)
            if action == "stop":
                args["action"] = "stop"
            elif action == "list":
                args["action"] = "list"
            elif action == "play_random":
                args["action"] = "play"
            elif action == "play_specific":
                args["action"] = "play"
                args["query"] = query
            else:
                # Fallback
                if "åœ" in user_input or "å…³" in user_input:
                    args["action"] = "stop"
                else:
                    args["action"] = "play"

        elif tool_name == "control_xiaomi_light":
            import re
            action = IntentMatcher.match_light_control(user_input)
            if action in ["on", "off"]:
                args["action"] = action
            elif "äº®" in user_input or "æš—" in user_input:
                args["action"] = "brightness"
                # default brightness
                value = 80 if "äº®" in user_input else 30
                m = re.search(r'(\d{1,3})', user_input)
                if m:
                    value = int(m.group(1))
                args["value"] = max(1, min(100, value))

        elif tool_name == "read_file":
            import re
            match = re.search(r'è¯»å–æ–‡ä»¶\s*([^\s]+)', user_input)
            if match: args["path"] = match.group(1)
            
        elif tool_name == "write_file":
            import re
            match = re.search(r'å†™å…¥æ–‡ä»¶\s*([^\s]+)\s*(.+)', user_input)
            if match:
                args["path"] = match.group(1)
                args["content"] = match.group(2)
                
        elif tool_name == "list_dir":
            import re
            match = re.search(r'æŸ¥çœ‹ç›®å½•\s*([^\s]+)', user_input)
            if match: args["path"] = match.group(1)
            
        elif tool_name == "send_email":
            # Basic extraction for simulation
            args["to"] = "user@example.com"
            args["subject"] = "Jarvis Notification"
            args["body"] = user_input
            
        elif tool_name == "add_calendar_event":
            args["event"] = user_input
            args["time"] = "æ˜å¤©"
            
        elif tool_name == "schedule_reminder":
            import re
            # Parse delay: "5ç§’å", "10åˆ†é’Ÿå"
            delay = 0
            match = re.search(r'(\d+)\s*(ç§’|åˆ†é’Ÿ|åˆ†|å°æ—¶|æ—¶)', user_input)
            if match:
                val = int(match.group(1))
                unit = match.group(2)
                if unit in ["ç§’"]: delay = val
                elif unit in ["åˆ†é’Ÿ", "åˆ†"]: delay = val * 60
                elif unit in ["å°æ—¶", "æ—¶"]: delay = val * 3600
            
            args["delay_seconds"] = max(delay, 5) # Minimum 5s
            
            # Parse description: remove trigger words and time
            desc = user_input
            for rm in ["æé†’", "æˆ‘", "å", match.group(0) if match else ""]:
                desc = desc.replace(rm, "")
            args["description"] = desc.strip() or "Reminder"
        
        return args
    
    async def execute_step(self, step: PlanStep, stream_callback: Optional[callable] = None) -> Optional[str]:
        """Execute a single plan step"""
        if step.tool_name is None:
            # For conversational steps, use LLM to generate response if not already present
            if not step.result or step.result == "Conversation response (no tool needed)":
                history = self.get_history(limit=5)
                prompt = f"""You are Jarvis. Respond to the user's request naturally.
[HISTORY]
{history}
[REQUEST]
{step.description}
"""
                step.result = await self._generate_conversational_response(prompt, stream_callback)
            step.status = StepStatus.SUCCESS
            return step.result
        
        if step.tool_name not in self.tools:
            step.status = StepStatus.FAILED
            step.error = f"Unknown tool: {step.tool_name}"
            return None
        
        try:
            tool = self.tools[step.tool_name]
            result = await tool.execute(**step.tool_args)
            
            # ğŸ”´ CRITICAL: Validate tool result to prevent hallucination
            if result is None or str(result).startswith("âŒ") or "Error" in str(result) or "error" in str(result):
                step.status = StepStatus.FAILED
                step.error = str(result) if result else "Tool returned empty result"
                step.result = None
                return None
            
            step.status = StepStatus.SUCCESS
            step.result = str(result)
            return step.result
        except Exception as e:
            step.status = StepStatus.FAILED
            step.error = str(e)
            return None

    def _get_personalized_system_prompt(self) -> str:
        """Build a personalized system prompt from user memory"""
        profile = self.memory.get_all_profile()
        basics = profile.get("basics", {})
        focus = profile.get("current_focus", {})
        interests = profile.get("interests", {})
        
        prompt = [
            "You are JARVIS, a helpful and sophisticated AI assistant.",
            "Your tone should be warm, intelligent, and natural, like a trusted friend (not overly formal).",
            "",
            "=== USER CONTEXT (USE THIS NATURALLY) ===",
        ]
        
        if basics.get("name"):
            prompt.append(f"- User Name: {basics['name']}")
        if basics.get("location"):
            prompt.append(f"- Location: {basics['location']}")
            
        if focus:
            prompt.append("- Current Focus/Projects:")
            for key, item in focus.items():
                if isinstance(item, dict) and "value" in item:
                    # New weighted format
                    prompt.append(f"  * {key}: {item['value']} (Mentioned {item.get('count', 1)} times)")
                else:
                    prompt.append(f"  * {key}: {item}")
        
        if interests:
            prompt.append("- Interests & Preferences:")
            for key, val in interests.items():
                prompt.append(f"  * {key}: {val}")
                
        prompt.extend([
            "",
            "=== INSTRUCTIONS ===",
            "1. Reference the user's focus/projects NATURALLY in a conversational way if relevant.",
            "2. Occasionally (but not every time) offer encouragement or ask about their progress.",
            "3. If the user asks who they are or what you remember, summarize this profile.",
            "4. Keep your responses concise and engaging for a voice interface.",
            "5. If you cannot answer a factual question (weather, stock, etc.) without tools, admit you need a tool.",
        ])
        
        return "\n".join(prompt)

    async def _generate_conversational_response(self, user_query: str, stream_callback: Optional[callable] = None) -> str:
        """
        Generate personalized conversational response using Doubao Realtime API.
        ğŸš€ OPTIMIZED: Uses /api/v3/responses with SSE streaming for sub-1s TTFT
        """
        import aiohttp
        import os
        import json
        import time
        
        api_key = os.getenv("DOUBAO_ARK_API_KEY")
        endpoint_id = os.getenv("DOUBAO_ENDPOINT_ID")
        
        if not api_key or not endpoint_id:
            # Fallback for demo
            context = self.memory.get_context_for_response()
            if "æ·±åº¦å­¦ä¹ " in user_query and context.get("learning") == "æ·±åº¦å­¦ä¹ ":
                return "å¥½çš„ï¼Œæ·±åº¦å­¦ä¹ æ˜¯ä¸€ä¸ªéå¸¸æœ‰æŒ‘æˆ˜ä½†ä¹Ÿéå¸¸æœ‰æˆå°±æ„Ÿçš„é¢†åŸŸï¼Œæˆ‘ä¼šé™ªä½ ä¸€èµ·æ”»å…‹å®ƒï¼"
            return "æ”¶åˆ°ï¼Œå…ˆç”Ÿã€‚æˆ‘ä¼šè®°åœ¨å¿ƒé‡Œã€‚"

        # Build input with conversation history (Responses API format)
        raw_history = self.memory.get_context(limit=6)
        
        # Convert to Responses API input format
        input_messages = []
        
        # Add conversation history
        role_map = {"user": "user", "assistant": "assistant", "bot": "assistant"}
        for entry in raw_history:
            role = role_map.get(entry['role'], "user")
            content = entry['content']
            if role == "user" and content == user_query:
                continue
            
            msg = {
                "type": "message", # ğŸ”¥ REQUIRED FOR RESPONSES API
                "role": role,
                "content": [{"type": "input_text" if role == "user" else "output_text", "text": content}]
            }
            if role == "assistant":
                msg["status"] = "completed"
            
            input_messages.append(msg)
        
        # Add current query
        input_messages.append({
            "type": "message", # ğŸ”¥ REQUIRED FOR RESPONSES API
            "role": "user",
            "content": [{"type": "input_text", "text": user_query}]
        })

        # ğŸš€ Use Responses API with THINKING DISABLED for ultra-low latency
        url = "https://ark.cn-beijing.volces.com/api/v3/responses"
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        
        # Optimization payload based on provided documentation
        payload = {
            "model": endpoint_id,
            "input": input_messages,
            "stream": True,
            "temperature": 0.7,
            "thinking": {
                "type": "disabled" # ğŸ”¥ TURN OFF REASONING FOR SPEED
            }
        }
        
        # Only add reasoning.effort for supported models
        if "lite" in endpoint_id or "251228" in endpoint_id or "251015" in endpoint_id:
            payload["reasoning"] = {"effort": "minimal"}
        
        full_content = ""
        first_token_received = False
        start_time = time.time()
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(url, headers=headers, json=payload, timeout=30) as resp:
                    if resp.status == 200:
                        print("ğŸ§  [Brain] Streaming...", end="", flush=True)
                        
                        async for line in resp.content:
                            line_str = line.decode('utf-8').strip()
                            
                            if not line_str or not line_str.startswith('data:'):
                                continue
                            
                            data_str = line_str[5:].strip()
                            if data_str == '[DONE]':
                                break
                            
                            try:
                                data = json.loads(data_str)
                                event_type = data.get('type', '')
                                
                                # âœ… Only process output_text delta events
                                if event_type == 'response.output_text.delta':
                                    chunk = data.get('delta', '')
                                    if chunk:
                                        if not first_token_received:
                                            first_token_received = True
                                            # print("", flush=True)  # Still need newline for first token
                                        full_content += chunk
                                        print(chunk, end="", flush=True)
                                        
                                        # ğŸš€ Invoke callback for streaming TTS
                                        if stream_callback:
                                            try:
                                                import inspect
                                                if inspect.iscoroutinefunction(stream_callback):
                                                    await stream_callback(chunk)
                                                else:
                                                    stream_callback(chunk)
                                            except Exception as cb_e:
                                                print(f"âš ï¸ Callback error: {cb_e}")
                                            
                            except json.JSONDecodeError:
                                pass
                        
                        print(" âœ…")
                        return full_content.strip()
                    else:
                        error_text = await resp.text()
                        print(f"âŒ Realtime API Error ({resp.status}): {error_text}")
                        
        except Exception as e:
            print(f"âŒ Realtime API connection error: {e}")
            
        return full_content.strip() if full_content else "æ”¶åˆ°ï¼Œå…ˆç”Ÿã€‚æˆ‘ä¼šç»§ç»­å…³æ³¨æ‚¨çš„éœ€æ±‚ã€‚"
    
    def synthesize(self, plan: ExecutionPlan) -> str:
        """Combine step results into final response"""
        if not plan.steps:
            return "I couldn't understand your request."
        
        results = []
        failed_count = 0
        
        # Check if this is a multi-stock query
        stock_steps = [s for s in plan.steps if s.tool_name == "get_stock_price" and s.status == StepStatus.SUCCESS]
        
        if len(stock_steps) > 1:
            # ğŸ¯ Smart merging for multiple stock queries
            stock_data = []
            for step in stock_steps:
                result = step.result
                # Extract the actual price data (remove redundant comments)
                # Format: "è¯„è®ºã€‚ å…¬å¸ï¼ˆä»£ç ï¼‰ç°ä»· X USDï¼Œä»Šæ—¥ä¸Šæ¶¨/ä¸‹è·Œäº† Y%ã€‚"
                import re
                match = re.search(r'([^\ã€‚]+ï¼ˆ[^\)]+ï¼‰ç°ä»·[^ã€‚]+ã€‚)', result)
                if match:
                    stock_data.append(match.group(1))
                else:
                    stock_data.append(result)
            
            # Combine all stocks in one sentence
            combined = " ".join(stock_data)
            results.append(combined)
            
            # Process remaining non-stock steps
            for step in plan.steps:
                if step.tool_name != "get_stock_price":
                    if step.status == StepStatus.SUCCESS and step.result:
                        results.append(step.result)
                    elif step.status == StepStatus.FAILED:
                        failed_count += 1
                        if step.tool_name:
                            error_msg = step.error or "unknown error"
                            results.append(f"æŠ±æ­‰ï¼Œ{step.tool_name}æ‰§è¡Œå¤±è´¥: {error_msg}")
                        else:
                            results.append(f"âš ï¸ {step.description} failed")
        else:
            # Normal synthesis for single-step or non-stock queries
            for step in plan.steps:
                if step.status == StepStatus.SUCCESS and step.result:
                    results.append(step.result)
                elif step.status == StepStatus.FAILED:
                    failed_count += 1
                    # ğŸ”´ CRITICAL: Be honest about failures - don't hallucinate success
                    if step.tool_name:
                        error_msg = step.error or "unknown error"
                        results.append(f"æŠ±æ­‰ï¼Œ{step.tool_name}æ‰§è¡Œå¤±è´¥: {error_msg}")
                    else:
                        results.append(f"âš ï¸ {step.description} failed")
        
        # If ALL steps failed, give a clearer error message
        if failed_count == len(plan.steps):
            return "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å®Œæˆè¿™ä¸ªè¯·æ±‚ã€‚" + ("\n".join(results) if results else "")
        
        base_response = "\n".join(results) if results else "Task completed."
        
        # ğŸ”¥ Personalization Enhancement
        enhanced_response = self._add_personal_touch(base_response)
        
        return enhanced_response
    
    def _add_personal_touch(self, response: str) -> str:
        """
        å¶å°”åœ¨å›å¤ä¸­åŠ å…¥å…³å¿ƒè¯­å¥ï¼ˆåŸºç¡€20%æ¦‚ç‡ï¼ŒéšæåŠæ¬¡æ•°å¢åŠ ï¼‰
        """
        import random
        
        # Skip if response is too short (likely a simple acknowledgment)
        if len(response) < 10:
            return response
        
        # Skip if it's an error message
        if "æŠ±æ­‰" in response or "å¤±è´¥" in response or "é”™è¯¯" in response:
            return response
        
        # Get context (with counts)
        context = self.memory.get_context_for_response()
        
        # Calculate dynamic probability based on mention counts
        # Base: 20%, +10% for each additional mention (max 80%)
        base_prob = 0.2
        max_count = max(
            context.get("project_count", 0),
            context.get("learning_count", 0),
            context.get("research_area_count", 0)
        )
        
        if max_count > 1:
            # Increase probability: 20% + 10% * (count-1), capped at 80%
            trigger_prob = min(0.8, base_prob + 0.1 * (max_count - 1))
        else:
            trigger_prob = base_prob
        
        # Random check
        if random.random() > trigger_prob:
            return response
        
        # Generate caring phrase based on context
        caring_phrases = []
        
        if "project" in context:
            caring_phrases = [
                f"\n\nå¯¹äº†ï¼Œ{context['project']}è¿›å±•é¡ºåˆ©å—ï¼Ÿ",
                f"\n\nè®ºæ–‡å†™å¾—æ€ä¹ˆæ ·äº†ï¼Ÿ",
                ""  # Empty = no addition sometimes
            ]
        elif "learning" in context:
            caring_phrases = [
                f"\n\n{context['learning']}å­¦å¾—æ€ä¹ˆæ ·äº†ï¼Ÿ",
                f"\n\næœ€è¿‘å­¦ä¹ æœ‰ä»€ä¹ˆæ–°æ”¶è·å—ï¼Ÿ",
                ""
            ]
        
        if caring_phrases:
            phrase = random.choice(caring_phrases)
            if phrase:  # Only add if not empty
                return response + phrase
        
        return response
    
    def get_history(self, limit: int = 5) -> str:
        """Get conversation history"""
        return self.memory.get_context_string(limit)


# Singleton instance
_agent_instance: Optional[JarvisAgent] = None


def get_agent() -> JarvisAgent:
    """Get the global agent instance"""
    global _agent_instance
    if _agent_instance is None:
        _agent_instance = JarvisAgent()
    return _agent_instance


# Quick test
if __name__ == "__main__":
    async def test():
        agent = get_agent()
        
        # Test 1: Time
        result = await agent.run("ç°åœ¨å‡ ç‚¹äº†")
        print(f"Result: {result}\n")
        
        # Test 2: Weather
        result = await agent.run("åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·")
        print(f"Result: {result}\n")
        
        # Test 3: Calculate
        result = await agent.run("è®¡ç®— 123 * 456")
        print(f"Result: {result}\n")
        
        # Test 4: History
        print("History:", agent.get_history())
    
    asyncio.run(test())
