#!/usr/bin/env python3
"""
JARVIS with xAI Grok Voice Agent API
çœŸæ­£çš„å®æ—¶è¯­éŸ³å¯¹è¯ - ç«¯åˆ°ç«¯éŸ³é¢‘
"""
import asyncio
import websockets
import json
import base64
import pyaudio
from rich.console import Console

console = Console()

# Configuration - Use environment variable for API key
import os
API_KEY = os.getenv("XAI_API_KEY", "your-xai-api-key-here")
WS_URL = "wss://api.x.ai/v1/realtime"
MODEL = "grok-2-public"

# Audio settings
SEND_SAMPLE_RATE = 24000
RECEIVE_SAMPLE_RATE = 24000
CHUNK_SIZE = 1024

SYSTEM_INSTRUCTION = """ä½ æ˜¯è´¾ç»´æ–¯ï¼ˆJARVISï¼‰ï¼Œä¸€ä¸ªé«˜çº§AIè¯­éŸ³åŠ©æ‰‹ã€‚
è¯·ç”¨**ä½æ²‰ã€ç¨³é‡çš„ç”·å£°**é£æ ¼å›ç­”ã€‚
åƒé’¢é“ä¾ çš„ç®¡å®¶ä¸€æ ·ï¼Œç”¨ç®€çŸ­ã€ä¸“ä¸šçš„ä¸­æ–‡å›å¤ã€‚
ä¸¥ç¦ä½¿ç”¨å¥³æ€§åŒ–è¯­æ°”ã€‚"""

class GrokVoice:
    def __init__(self):
        self.audio = pyaudio.PyAudio()
        self.running = True
        self.is_speaking = False  # å½“ Grok è¯´è¯æ—¶æš‚åœå½•éŸ³
        
    async def connect(self):
        """Connect to Grok Voice API"""
        headers = {
            "Authorization": f"Bearer {API_KEY}",
            "Content-Type": "application/json"
        }
        
        console.print("ğŸš€ æ­£åœ¨è¿æ¥åˆ° Grok Voice...", style="yellow")
        
        async with websockets.connect(WS_URL, additional_headers=headers) as ws:
            console.print("âœ… å·²è¿æ¥åˆ° Grok Voice!", style="bold green")
            
            # Send session configuration
            session_config = {
                "type": "session.update",
                "session": {
                    "modalities": ["text", "audio"],
                    "instructions": SYSTEM_INSTRUCTION,
                    "voice": "onyx",
                    "input_audio_format": "pcm16",
                    "output_audio_format": "pcm16",
                    "input_audio_transcription": {
                        "model": "whisper-1"
                    },
                    "turn_detection": {
                        "type": "server_vad",
                        "threshold": 0.2,
                        "prefix_padding_ms": 300,
                        "silence_duration_ms": 800
                    }
                }
            }
            await ws.send(json.dumps(session_config))
            
            console.print("ğŸ’¬ ç°åœ¨å¯ä»¥ç›´æ¥å¯¹è¯äº†ï¼ŒæŒ‰ Ctrl+C é€€å‡º", style="cyan")
            console.print("=" * 50)
            
            # Run tasks concurrently
            await asyncio.gather(
                self.send_audio(ws),
                self.receive_audio(ws)
            )
    
    async def send_audio(self, ws):
        """Capture and send audio to Grok"""
        stream = self.audio.open(
            format=pyaudio.paInt16,
            channels=1,
            rate=SEND_SAMPLE_RATE,
            input=True,
            frames_per_buffer=CHUNK_SIZE
        )
        
        console.print("ğŸ¤ éº¦å…‹é£å·²å¼€å¯", style="dim")
        
        try:
            chunk_count = 0
            while self.running:
                data = await asyncio.to_thread(
                    stream.read, CHUNK_SIZE, exception_on_overflow=False
                )
                
                # Debug: show audio level every 50 chunks
                chunk_count += 1
                if chunk_count % 50 == 0:
                    import numpy as np
                    audio_data = np.frombuffer(data, dtype=np.int16)
                    level = np.abs(audio_data).mean()
                    console.print(f"ğŸ¤ éŸ³é‡: {level:.0f}", style="dim", end="\r")
                
                # å¦‚æœ Grok æ­£åœ¨è¯´è¯ï¼Œä¸å‘é€éŸ³é¢‘ï¼ˆé¿å…å›å£°ï¼‰
                if self.is_speaking:
                    continue
                
                # Encode audio as base64
                audio_b64 = base64.b64encode(data).decode('utf-8')
                
                # Send audio event
                event = {
                    "type": "input_audio_buffer.append",
                    "audio": audio_b64
                }
                await ws.send(json.dumps(event))
                
        except Exception as e:
            console.print(f"éº¦å…‹é£é”™è¯¯: {e}", style="red")
        finally:
            stream.stop_stream()
            stream.close()
    
    async def receive_audio(self, ws):
        """Receive and play audio from Grok"""
        stream = self.audio.open(
            format=pyaudio.paInt16,
            channels=1,
            rate=RECEIVE_SAMPLE_RATE,
            output=True,
            frames_per_buffer=CHUNK_SIZE
        )
        
        try:
            async for message in ws:
                event = json.loads(message)
                event_type = event.get("type", "")
                
                # Debug: print all event types
                if event_type not in ["input_audio_buffer.speech_started", "input_audio_buffer.speech_stopped", "session.updated", "session.created"]:
                    console.print(f"[DEBUG] äº‹ä»¶: {event_type}", style="dim magenta")
                
                if event_type == "response.output_audio.delta":
                    # Play audio
                    audio_b64 = event.get("delta", "")
                    if audio_b64:
                        audio_data = base64.b64decode(audio_b64)
                        console.print(f"ğŸ”Š æ’­æ”¾éŸ³é¢‘ ({len(audio_data)} bytes)", style="dim")
                        await asyncio.to_thread(stream.write, audio_data)
                
                elif event_type == "response.output_audio_transcript.delta":
                    # Print transcript
                    text = event.get("delta", "")
                    if text:
                        console.print(text, end="", style="cyan")
                
                elif event_type == "response.output_audio_transcript.done":
                    console.print()  # New line
                
                elif event_type == "input_audio_buffer.speech_started":
                    console.print("ğŸ‘‚ å¬åˆ°äº†...", style="dim")
                
                elif event_type == "input_audio_buffer.speech_stopped":
                    console.print("ğŸ”„ å¤„ç†ä¸­...", style="dim")
                
                elif event_type == "response.created":
                    self.is_speaking = True  # å¼€å§‹è¯´è¯ï¼Œæš‚åœå½•éŸ³
                    console.print("ğŸ’¬ å›å¤ä¸­...", style="green")
                
                elif event_type == "response.done":
                    self.is_speaking = False  # è¯´å®Œäº†ï¼Œæ¢å¤å½•éŸ³
                    console.print("", style="")  # Done
                
                elif event_type == "session.created":
                    console.print("ğŸ“¡ ä¼šè¯å·²åˆ›å»º", style="dim")
                
                elif event_type == "session.updated":
                    console.print("âš™ï¸  ä¼šè¯å·²é…ç½®", style="dim")
                
                elif event_type == "error":
                    error = event.get("error", {})
                    console.print(f"âŒ é”™è¯¯: {error.get('message', error)}", style="red")
                    
        except Exception as e:
            console.print(f"æ¥æ”¶é”™è¯¯: {e}", style="red")
        finally:
            stream.stop_stream()
            stream.close()
    
    def cleanup(self):
        self.running = False
        self.audio.terminate()

async def main():
    voice = GrokVoice()
    try:
        await voice.connect()
    except KeyboardInterrupt:
        console.print("\nğŸ‘‹ å†è§!", style="cyan")
    except Exception as e:
        console.print(f"é”™è¯¯: {e}", style="red")
        import traceback
        traceback.print_exc()
    finally:
        voice.cleanup()

if __name__ == "__main__":
    asyncio.run(main())
